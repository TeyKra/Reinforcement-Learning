# TP1 Reinforcement-Learning

### Dynamic Programming for Reinforcement Learning in Maze Environments

This project explores **value iteration** and **policy iteration** algorithms in a maze environment modeled as a Markov Decision Process (MDP). The objective is to find optimal policies that maximize the agent's total expected reward.

The notebook demonstrates the implementation of **value iteration** and **policy iteration** using both state value functions (V) and state-action value functions (Q). These foundational algorithms provide insights into dynamic programming techniques widely used in reinforcement learning.

The study includes a comparative analysis of the computational efficiency of these methods in terms of iterations, operations, and execution time. Visualization of convergence rates offers a deeper understanding of their performance.

Dependencies are installed automatically, and the environment setup generates random mazes for experimental evaluation.
